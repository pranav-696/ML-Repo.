{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/pranav-696/ML-Repo./blob/main/DFD.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import cv2\n",
        "import os\n",
        "import shutil\n",
        "import dlib\n",
        "from PIL import Image"
      ],
      "metadata": {
        "id": "iTcOu7xofAXo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "img_file = \"Frame_img\"\n",
        "crop_image_file = \"crop_img\"\n",
        "\n",
        "if(os.path.isdir(img_file) == True):\n",
        "    shutil.rmtree(img_file)\n",
        "os.mkdir(img_file)\n",
        "\n",
        "if(os.path.isdir(crop_image_file) == True):\n",
        "    shutil.rmtree(crop_image_file)\n",
        "os.mkdir(crop_image_file)"
      ],
      "metadata": {
        "id": "homG-zLZfPgt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "video_path = '/content/id56_0005.mp4'\n",
        "\n",
        "if(os.path.isdir(img_file) == True):\n",
        "    shutil.rmtree(img_file)\n",
        "os.mkdir(img_file)\n",
        "\n",
        "capture = cv2.VideoCapture(video_path)\n",
        "f = 0\n",
        "intrval = 12\n",
        "save_frame = 0\n",
        "while(capture.isOpened()):\n",
        "    ret, frame = capture.read()\n",
        "    if ret == False:\n",
        "        break\n",
        "    if f % intrval == 0:\n",
        "        cv2.imwrite('Frame_img/imgf'+str(f)+'.jpg',frame)\n",
        "        save_frame += 1\n",
        "    f += 1"
      ],
      "metadata": {
        "id": "nLQBwtIPf8r6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def detect_and_crop_face_dlib(image_path, output_path):\n",
        "    # Load the image using dlib\n",
        "    img = dlib.load_rgb_image(image_path)\n",
        "\n",
        "    # Initialize dlib's face detector (HOG-based)\n",
        "    detector = dlib.get_frontal_face_detector()\n",
        "\n",
        "    # Detect faces in the image\n",
        "    faces = detector(img, 1)\n",
        "\n",
        "    # Check if any faces are detected\n",
        "    if len(faces) == 0:\n",
        "        print(\"No faces detected\")\n",
        "        return None\n",
        "\n",
        "    # Loop over the detected faces\n",
        "    for face in faces:\n",
        "        x, y, w, h = face.left(), face.top(), face.width(), face.height()\n",
        "\n",
        "        # Crop the face from the image\n",
        "        cropped_face = Image.fromarray(img[y:y+h, x:x+w])\n",
        "\n",
        "        # Save the cropped face\n",
        "        cropped_face.save(output_path)\n",
        "\n",
        "        # Return the cropped face\n",
        "        return cropped_face\n",
        "\n",
        "# Example usage\n",
        "k= 10\n",
        "j = 7\n",
        "for filename in os.listdir(img_file):\n",
        "  if(filename.endswith('.jpg') == True):\n",
        "    cropped_face = detect_and_crop_face_dlib('Frame_img/'+filename, crop_image_file+'/img_crop'+str(k)+str(j)+'.jpg' )\n",
        "    if cropped_face is not None:\n",
        "        print(\"Face cropped and saved successfully.\")\n",
        "    k+=1"
      ],
      "metadata": {
        "id": "AdSzkASgd80X",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b9d52fd1-3b47-4b63-b7af-2cd47abaabb4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Face cropped and saved successfully.\n",
            "Face cropped and saved successfully.\n",
            "Face cropped and saved successfully.\n",
            "Face cropped and saved successfully.\n",
            "Face cropped and saved successfully.\n",
            "Face cropped and saved successfully.\n",
            "Face cropped and saved successfully.\n",
            "Face cropped and saved successfully.\n",
            "Face cropped and saved successfully.\n",
            "Face cropped and saved successfully.\n",
            "Face cropped and saved successfully.\n",
            "Face cropped and saved successfully.\n",
            "Face cropped and saved successfully.\n",
            "Face cropped and saved successfully.\n",
            "Face cropped and saved successfully.\n",
            "Face cropped and saved successfully.\n",
            "Face cropped and saved successfully.\n",
            "Face cropped and saved successfully.\n",
            "Face cropped and saved successfully.\n",
            "Face cropped and saved successfully.\n",
            "Face cropped and saved successfully.\n",
            "Face cropped and saved successfully.\n",
            "Face cropped and saved successfully.\n",
            "Face cropped and saved successfully.\n",
            "Face cropped and saved successfully.\n",
            "Face cropped and saved successfully.\n",
            "Face cropped and saved successfully.\n",
            "Face cropped and saved successfully.\n",
            "Face cropped and saved successfully.\n",
            "Face cropped and saved successfully.\n",
            "Face cropped and saved successfully.\n",
            "Face cropped and saved successfully.\n",
            "Face cropped and saved successfully.\n",
            "Face cropped and saved successfully.\n",
            "Face cropped and saved successfully.\n",
            "Face cropped and saved successfully.\n",
            "Face cropped and saved successfully.\n",
            "Face cropped and saved successfully.\n",
            "Face cropped and saved successfully.\n",
            "Face cropped and saved successfully.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# for filename in os.listdir(crop_image_file):\n",
        "#     if filename.endswith('.jpg'):\n",
        "#         new_filename = \"h_056\" + filename\n",
        "#         # Construct the full file paths\n",
        "#         old_file = os.path.join(crop_image_file, filename)\n",
        "#         new_file = os.path.join(crop_image_file, new_filename)\n",
        "\n",
        "#         # Rename the file\n",
        "#         os.rename(old_file, new_file)"
      ],
      "metadata": {
        "id": "R-cWwJme7iVH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# from google.colab import files\n",
        "\n",
        "# # Step 1: Zip the folder\n",
        "# shutil.make_archive(crop_image_file, 'zip', '/content/crop_img' )\n",
        "\n",
        "# # Step 2: Download the zipped folder\n",
        "# files.download('crop_img.zip')"
      ],
      "metadata": {
        "id": "D2JAiNSsIHRB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "MAIN CODE IS FROM HERE ON"
      ],
      "metadata": {
        "id": "OYnsNm4CIIlC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "f_imgs = []\n",
        "\n",
        "for filename in os.listdir(crop_image_file):\n",
        "  if filename.endswith('.jpg'):\n",
        "    filepath = os.path.join(crop_image_file, filename)\n",
        "    img = Image.open(filepath)\n",
        "    f_imgs.append({\n",
        "        'filename': filename,\n",
        "        'filepath': filepath,\n",
        "        'width' : img.width,\n",
        "        'height' : img.height\n",
        "    })"
      ],
      "metadata": {
        "id": "0uNCUdn3FrPj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "def pixel_error(image):\n",
        "  gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)  # represent the image in grey scale\n",
        "  laplacin_measure = cv2.Laplacian(gray, cv2.CV_64F).var()\n",
        "  return int(laplacin_measure < 100)"
      ],
      "metadata": {
        "id": "EntC2c-WOey_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def shadow_inconsistncies(image):\n",
        "    gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
        "\n",
        "    threshold = cv2.adaptiveThreshold(gray, 255, cv2.ADAPTIVE_THRESH_GAUSSIAN_C,\n",
        "                                      cv2.THRESH_BINARY_INV, 11, 2)\n",
        "\n",
        "    kernel = np.ones((5, 5), np.uint8)\n",
        "    clean_mask = cv2.morphologyEx(threshold, cv2.MORPH_CLOSE, kernel)\n",
        "\n",
        "    shadow_pixels = np.sum(clean_mask == 255)\n",
        "\n",
        "    shadow_pixel_threshold = 0.2 * (image.shape[0] * image.shape[1])\n",
        "\n",
        "    if shadow_pixels > shadow_pixel_threshold:\n",
        "        return 0  # Shadow inconsistency detected\n",
        "    else:\n",
        "        return 1"
      ],
      "metadata": {
        "id": "HmVHo11mOfGD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import dlib\n",
        "\n",
        "detector = dlib.get_frontal_face_detector()\n",
        "predictor = dlib.shape_predictor(\"shape_predictor_68_face_landmarks.dat\")\n",
        "\n",
        "def face_landmark_misalignment(image):\n",
        "  gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
        "  faces = detector(gray)\n",
        "  misalignment_detected =[]\n",
        "\n",
        "  for face in faces:\n",
        "    landmarks = predictor(gray, face)\n",
        "    landmarks_np = np.array([(landmarks.part(i).x, landmarks.part(i).y) for i in range(68)])\n",
        "\n",
        "    left_eye = landmarks_np[36:42]\n",
        "    right_eye = landmarks_np[42:48]\n",
        "    left_eye_center = np.mean(left_eye, axis=0)\n",
        "    right_eye_center = np.mean(right_eye, axis=0)\n",
        "    eye_asymmetry = abs(left_eye_center[1] - right_eye_center[1])\n",
        "\n",
        "    interocular_distance = np.linalg.norm(left_eye_center - right_eye_center)\n",
        "    eye_asymmetry_threshold = 0.05 * interocular_distance\n",
        "\n",
        "    if eye_asymmetry > eye_asymmetry_threshold:\n",
        "        misalignment_detected.append(1) #'Eye Asymmetry'\n",
        "\n",
        "    nose_tip = landmarks_np[30]\n",
        "    face_center_x = (landmarks_np[0, 0] + landmarks_np[16, 0])\n",
        "    nose_deviation = abs(nose_tip[0] - face_center_x)\n",
        "\n",
        "    face_width = landmarks_np[16, 0] - landmarks_np[0, 0]\n",
        "    nose_deviation_threshold = 0.1 * face_width\n",
        "\n",
        "    if nose_deviation > nose_deviation_threshold:\n",
        "        misalignment_detected.append(2) #'Nose Deviation'\n",
        "\n",
        "    left_mouth_corner = landmarks_np[48]\n",
        "    right_mouth_corner = landmarks_np[54]\n",
        "    mouth_skewness = abs(left_mouth_corner[1] - right_mouth_corner[1])\n",
        "\n",
        "    mouth_width = np.linalg.norm(left_mouth_corner - right_mouth_corner)\n",
        "    mouth_skewness_threshold = 0.1 * mouth_width\n",
        "\n",
        "    if mouth_skewness > mouth_skewness_threshold:\n",
        "        misalignment_detected.append(3) #'Mouth Skewness'\n",
        "\n",
        "    chin_point = landmarks_np[8]  # Chin point\n",
        "    chin_deviation = abs(chin_point[0] - face_center_x)\n",
        "\n",
        "    chin_deviation_threshold = 0.08 * face_width\n",
        "\n",
        "    if chin_deviation > chin_deviation_threshold:\n",
        "        misalignment_detected.append(4) #'Chin Displacement'\n",
        "\n",
        "  return misalignment_detected"
      ],
      "metadata": {
        "id": "XPjf1lwZOfW2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install pyngrok"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KnYiYlm09ad9",
        "outputId": "40ecba6f-3c7a-48fb-9308-5dc167354404"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting pyngrok\n",
            "  Downloading pyngrok-7.2.0-py3-none-any.whl.metadata (7.4 kB)\n",
            "Requirement already satisfied: PyYAML>=5.1 in /usr/local/lib/python3.10/dist-packages (from pyngrok) (6.0.2)\n",
            "Downloading pyngrok-7.2.0-py3-none-any.whl (22 kB)\n",
            "Installing collected packages: pyngrok\n",
            "Successfully installed pyngrok-7.2.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pixel_anomaly = {}\n",
        "shadow_anomaly = {}\n",
        "landmark_anomaly = {}\n",
        "\n",
        "for img_info in f_imgs:\n",
        "  image = cv2.imread(img_info['filepath'])\n",
        "  if image is not None:\n",
        "    pixel_anomaly= pixel_error(image)\n",
        "    shadow_anomaly = shadow_inconsistncies(image)\n",
        "    landmark_anomaly = face_landmark_misalignment(image)\n",
        "\n",
        "    Eye_Asymmetry = 0\n",
        "    Nose_Deviation = 0\n",
        "    Mouth_Skewness = 0\n",
        "    Chin_Displacement = 0\n",
        "\n",
        "    for i in landmark_anomaly:\n",
        "      if(i==1):\n",
        "        Eye_Asymmetry = 1\n",
        "      elif(i==2):\n",
        "        Nose_Deviation = 1\n",
        "      elif(i==3):\n",
        "        Mouth_Skewness = 1\n",
        "      elif(i==4):\n",
        "        Chin_Displacement = 1\n",
        "\n",
        "\n",
        "    img_info.update({\n",
        "        'pixelation': pixel_anomaly,\n",
        "        'shadow_inconsistency': shadow_anomaly,\n",
        "        'Eye_Asymmetry': Eye_Asymmetry,\n",
        "        'Nose_Deviation': Nose_Deviation,\n",
        "        'Mouth_Skewness': Mouth_Skewness,\n",
        "        'Chin_Displacement': Chin_Displacement\n",
        "    })\n",
        "  else:\n",
        "    print(\"Image not found\")\n"
      ],
      "metadata": {
        "id": "UOkfF-Vod8Q9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "ZpuwKI6t9X62",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a0f51abb-ee9d-457a-fb0b-6eb0b7b5de3a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "real_images_dir = '/content/drive/MyDrive/Train_img/real'\n",
        "fake_images_dir = '/content/drive/MyDrive/Train_img/fake'\n",
        "\n",
        "image_list = []\n",
        "\n",
        "for filename in os.listdir(real_images_dir):\n",
        "  if filename.endswith('.jpg'):\n",
        "    filepath = os.path.join(real_images_dir, filename)\n",
        "\n",
        "    img = cv2.imread(filepath)\n",
        "    img_dimention = Image.open(filepath)\n",
        "\n",
        "    pixel_anomaly= pixel_error(img)\n",
        "    shadow_anomaly = shadow_inconsistncies(img)\n",
        "    landmark_anomaly = face_landmark_misalignment(img)\n",
        "\n",
        "    Eye_Asymmetry = 0\n",
        "    Nose_Deviation = 0\n",
        "    Mouth_Skewness = 0\n",
        "    Chin_Displacement = 0\n",
        "    img = Image.open(filepath)\n",
        "\n",
        "    if(len(landmark_anomaly)!=0):\n",
        "      for i in landmark_anomaly:\n",
        "        if(i==1):\n",
        "          Eye_Asymmetry = 1\n",
        "        elif(i==2):\n",
        "          Nose_Deviation = 1\n",
        "        elif(i==3):\n",
        "          Mouth_Skewness = 1\n",
        "        elif(i==4):\n",
        "          Chin_Displacement = 1\n",
        "\n",
        "    image_list.append({\n",
        "        'filename': filename,\n",
        "        'image_path': filepath,\n",
        "        'width' : img_dimention.width,\n",
        "        'height' : img_dimention.height,\n",
        "        'real_fake_label' : 0,\n",
        "        'pixelation': pixel_anomaly,\n",
        "        'shadow_inconsistency': shadow_anomaly,\n",
        "        'eye_asymmetry': Eye_Asymmetry,\n",
        "        'nose_deviation': Nose_Deviation,\n",
        "        'mouth_skewness': Mouth_Skewness,\n",
        "        'chin_displacement': Chin_Displacement\n",
        "    })\n",
        "\n",
        "\n",
        "for filename in os.listdir(fake_images_dir):\n",
        "  if filename.endswith('.jpg'):\n",
        "    filepath = os.path.join(fake_images_dir, filename)\n",
        "\n",
        "    img = cv2.imread(filepath)\n",
        "    img_dimention = Image.open(filepath)\n",
        "\n",
        "    pixel_anomaly= pixel_error(img)\n",
        "    shadow_anomaly = shadow_inconsistncies(img)\n",
        "    landmark_anomaly = face_landmark_misalignment(img)\n",
        "\n",
        "    Eye_Asymmetry = 0\n",
        "    Nose_Deviation = 0\n",
        "    Mouth_Skewness = 0\n",
        "    Chin_Displacement = 0\n",
        "\n",
        "    if(len(landmark_anomaly)!=0):\n",
        "      for i in landmark_anomaly:\n",
        "        if(i==1):\n",
        "          Eye_Asymmetry = 1\n",
        "        elif(i==2):\n",
        "          Nose_Deviation = 1\n",
        "        elif(i==3):\n",
        "          Mouth_Skewness = 1\n",
        "        elif(i==4):\n",
        "          Chin_Displacement = 1\n",
        "\n",
        "    image_list.append({\n",
        "        'filename': filename,\n",
        "        'image_path': filepath,\n",
        "        'width' : img_dimention.width,\n",
        "        'height' : img_dimention.height,\n",
        "        'real_fake_label' : 1,\n",
        "        'pixelation': pixel_anomaly,\n",
        "        'shadow_inconsistency': shadow_anomaly,\n",
        "        'eye_asymmetry': Eye_Asymmetry,\n",
        "        'nose_deviation': Nose_Deviation,\n",
        "        'mouth_skewness': Mouth_Skewness,\n",
        "        'chin_displacement': Chin_Displacement\n",
        "    })\n"
      ],
      "metadata": {
        "id": "T1KxtLpmmHZY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "df = pd.DataFrame(image_list)"
      ],
      "metadata": {
        "id": "EccyJ3CpGnYZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.head()"
      ],
      "metadata": {
        "id": "J_AyLM4VMBcU",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 226
        },
        "outputId": "de3ccd29-b659-4d7b-c75e-b9ae4136b74a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "               filename                                         image_path  \\\n",
              "0  r_356img_crop695.jpg  /content/drive/MyDrive/Train_img/real/r_356img...   \n",
              "1  r_356img_crop738.jpg  /content/drive/MyDrive/Train_img/real/r_356img...   \n",
              "2  r_356img_crop739.jpg  /content/drive/MyDrive/Train_img/real/r_356img...   \n",
              "3  r_356img_crop737.jpg  /content/drive/MyDrive/Train_img/real/r_356img...   \n",
              "4  r_356img_crop658.jpg  /content/drive/MyDrive/Train_img/real/r_356img...   \n",
              "\n",
              "   width  height  real_fake_label  pixelation  shadow_inconsistency  \\\n",
              "0    156     156                0           1                     0   \n",
              "1    268     269                0           1                     1   \n",
              "2    186     187                0           1                     0   \n",
              "3    269     268                0           1                     0   \n",
              "4    187     187                0           1                     0   \n",
              "\n",
              "   eye_asymmetry  nose_deviation  mouth_skewness  chin_displacement  \n",
              "0              1               1               1                  1  \n",
              "1              0               0               0                  0  \n",
              "2              1               0               1                  1  \n",
              "3              1               0               1                  1  \n",
              "4              1               1               1                  1  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-9166252f-e812-49ab-a3f7-e66326328285\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>filename</th>\n",
              "      <th>image_path</th>\n",
              "      <th>width</th>\n",
              "      <th>height</th>\n",
              "      <th>real_fake_label</th>\n",
              "      <th>pixelation</th>\n",
              "      <th>shadow_inconsistency</th>\n",
              "      <th>eye_asymmetry</th>\n",
              "      <th>nose_deviation</th>\n",
              "      <th>mouth_skewness</th>\n",
              "      <th>chin_displacement</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>r_356img_crop695.jpg</td>\n",
              "      <td>/content/drive/MyDrive/Train_img/real/r_356img...</td>\n",
              "      <td>156</td>\n",
              "      <td>156</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>r_356img_crop738.jpg</td>\n",
              "      <td>/content/drive/MyDrive/Train_img/real/r_356img...</td>\n",
              "      <td>268</td>\n",
              "      <td>269</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>r_356img_crop739.jpg</td>\n",
              "      <td>/content/drive/MyDrive/Train_img/real/r_356img...</td>\n",
              "      <td>186</td>\n",
              "      <td>187</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>r_356img_crop737.jpg</td>\n",
              "      <td>/content/drive/MyDrive/Train_img/real/r_356img...</td>\n",
              "      <td>269</td>\n",
              "      <td>268</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>r_356img_crop658.jpg</td>\n",
              "      <td>/content/drive/MyDrive/Train_img/real/r_356img...</td>\n",
              "      <td>187</td>\n",
              "      <td>187</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-9166252f-e812-49ab-a3f7-e66326328285')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-9166252f-e812-49ab-a3f7-e66326328285 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-9166252f-e812-49ab-a3f7-e66326328285');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-37be84ed-6e85-4dff-8aa2-e5314aba4f52\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-37be84ed-6e85-4dff-8aa2-e5314aba4f52')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-37be84ed-6e85-4dff-8aa2-e5314aba4f52 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "df",
              "summary": "{\n  \"name\": \"df\",\n  \"rows\": 1374,\n  \"fields\": [\n    {\n      \"column\": \"filename\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 1374,\n        \"samples\": [\n          \"b_444img_crop675.jpg\",\n          \"img_crop371.jpg\",\n          \"u_944img_crop740.jpg\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"image_path\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 1374,\n        \"samples\": [\n          \"/content/drive/MyDrive/Train_img/real/b_444img_crop675.jpg\",\n          \"/content/drive/MyDrive/Train_img/real/img_crop371.jpg\",\n          \"/content/drive/MyDrive/Train_img/real/u_944img_crop740.jpg\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"width\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 45,\n        \"min\": 53,\n        \"max\": 322,\n        \"num_unique_values\": 18,\n        \"samples\": [\n          156,\n          268,\n          155\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"height\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 45,\n        \"min\": 53,\n        \"max\": 322,\n        \"num_unique_values\": 16,\n        \"samples\": [\n          156,\n          269,\n          224\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"real_fake_label\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 0,\n        \"max\": 1,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          1,\n          0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"pixelation\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 0,\n        \"max\": 1,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          0,\n          1\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"shadow_inconsistency\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 0,\n        \"max\": 1,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          1,\n          0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"eye_asymmetry\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 0,\n        \"max\": 1,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          0,\n          1\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"nose_deviation\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 0,\n        \"max\": 1,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          0,\n          1\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"mouth_skewness\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 0,\n        \"max\": 1,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          0,\n          1\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"chin_displacement\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 0,\n        \"max\": 1,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          0,\n          1\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df.info()"
      ],
      "metadata": {
        "id": "U8TDUYRRMGL0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "77fe9aec-530a-4ef5-ad57-44f117fd5871"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 1374 entries, 0 to 1373\n",
            "Data columns (total 11 columns):\n",
            " #   Column                Non-Null Count  Dtype \n",
            "---  ------                --------------  ----- \n",
            " 0   filename              1374 non-null   object\n",
            " 1   image_path            1374 non-null   object\n",
            " 2   width                 1374 non-null   int64 \n",
            " 3   height                1374 non-null   int64 \n",
            " 4   real_fake_label       1374 non-null   int64 \n",
            " 5   pixelation            1374 non-null   int64 \n",
            " 6   shadow_inconsistency  1374 non-null   int64 \n",
            " 7   eye_asymmetry         1374 non-null   int64 \n",
            " 8   nose_deviation        1374 non-null   int64 \n",
            " 9   mouth_skewness        1374 non-null   int64 \n",
            " 10  chin_displacement     1374 non-null   int64 \n",
            "dtypes: int64(9), object(2)\n",
            "memory usage: 118.2+ KB\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.preprocessing.image import load_img, img_to_array\n",
        "from tensorflow.keras.utils import Sequence\n",
        "\n",
        "class DataFrameGenerator(Sequence):\n",
        "    def __init__(self, df, batch_size, img_size, shuffle=True):\n",
        "        self.df = df\n",
        "        self.batch_size = batch_size\n",
        "        self.img_size = img_size\n",
        "        self.shuffle = shuffle\n",
        "        self.on_epoch_end()\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.df) // self.batch_size\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        batch_df = self.df.iloc[index * self.batch_size:(index + 1) * self.batch_size]\n",
        "        images = []\n",
        "        real_fake_labels = []\n",
        "        pixelation_labels = []\n",
        "        shadow_labels = []\n",
        "        eye_asymmetry_labels = []\n",
        "        mouth_skewness_labels = []\n",
        "        nose_deviation_labels = []\n",
        "        chin_displacement_labels = []\n",
        "\n",
        "        for _, row in batch_df.iterrows():\n",
        "            img = load_img(row['image_path'], target_size=self.img_size)\n",
        "            img = img_to_array(img) / 255.0  # Normalize the image\n",
        "\n",
        "            images.append(img)\n",
        "            real_fake_labels.append(row['real_fake_label'])\n",
        "            pixelation_labels.append(row['pixelation'])\n",
        "            shadow_labels.append(row['shadow_inconsistency'])\n",
        "            eye_asymmetry_labels.append(row['eye_asymmetry'])\n",
        "            mouth_skewness_labels.append(row['mouth_skewness'])\n",
        "            nose_deviation_labels.append(row['nose_deviation'])\n",
        "            chin_displacement_labels.append(row['chin_displacement'])\n",
        "\n",
        "        return np.array(images), {\n",
        "            'real_fake_output': np.array(real_fake_labels),\n",
        "            'pixelation_output': np.array(pixelation_labels),\n",
        "            'shadow_output': np.array(shadow_labels),\n",
        "            'eye_asymmetry_output': np.array(eye_asymmetry_labels),\n",
        "            'mouth_skewness_output': np.array(mouth_skewness_labels),\n",
        "            'nose_deviation_output': np.array(nose_deviation_labels),\n",
        "            'chin_displacement_output': np.array(chin_displacement_labels)\n",
        "        }\n",
        "\n",
        "    def on_epoch_end(self):\n",
        "        if self.shuffle:\n",
        "            self.df = self.df.sample(frac=1).reset_index(drop=True)"
      ],
      "metadata": {
        "id": "k0wUf5ALlxlp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout, Input\n",
        "\n",
        "# Define the CNN model with multiple outputs including specific facial abnormalities\n",
        "def create_multi_error_detection_model():\n",
        "    inputs = Input(shape=(128, 128, 3))\n",
        "\n",
        "    # Shared layers\n",
        "    x = Conv2D(32, (3, 3), activation='relu')(inputs)\n",
        "    x = MaxPooling2D((2, 2))(x)\n",
        "    x = Conv2D(64, (3, 3), activation='relu')(x)\n",
        "    x = MaxPooling2D((2, 2))(x)\n",
        "    x = Conv2D(128, (3, 3), activation='relu')(x)\n",
        "    x = MaxPooling2D((2, 2))(x)\n",
        "    x = Flatten()(x)\n",
        "    x = Dense(128, activation='relu')(x)\n",
        "    x = Dropout(0.5)(x)\n",
        "\n",
        "    # Output 1: Real/Fake classification\n",
        "    real_fake_output = Dense(1, activation='sigmoid', name='real_fake_output')(x)\n",
        "\n",
        "    # Output 2: Pixelation classification\n",
        "    pixelation_output = Dense(1, activation='sigmoid', name='pixelation_output')(x)\n",
        "\n",
        "    # Output 3: Shadow Inconsistency classification\n",
        "    shadow_output = Dense(1, activation='sigmoid', name='shadow_output')(x)\n",
        "\n",
        "    # Output 4: Eye Asymmetry classification\n",
        "    eye_asymmetry_output = Dense(1, activation='sigmoid', name='eye_asymmetry_output')(x)\n",
        "\n",
        "    # Output 5: Mouth Skewness classification\n",
        "    mouth_skewness_output = Dense(1, activation='sigmoid', name='mouth_skewness_output')(x)\n",
        "\n",
        "    # Output 6: Nose Deviation classification\n",
        "    nose_deviation_output = Dense(1, activation='sigmoid', name='nose_deviation_output')(x)\n",
        "\n",
        "    # Output 7: Chin Displacement classification\n",
        "    chin_displacement_output = Dense(1, activation='sigmoid', name='chin_displacement_output')(x)\n",
        "\n",
        "    # Define the model\n",
        "    model = Model(inputs=inputs, outputs=[real_fake_output, pixelation_output, shadow_output, eye_asymmetry_output, mouth_skewness_output, nose_deviation_output, chin_displacement_output])\n",
        "\n",
        "    # Compile the model with separate loss functions\n",
        "    model.compile(\n",
        "        optimizer='adam',\n",
        "        loss={\n",
        "            'real_fake_output': 'binary_crossentropy',\n",
        "            'pixelation_output': 'binary_crossentropy',\n",
        "            'shadow_output': 'binary_crossentropy',\n",
        "            'eye_asymmetry_output': 'binary_crossentropy',\n",
        "            'mouth_skewness_output': 'binary_crossentropy',\n",
        "            'nose_deviation_output': 'binary_crossentropy',\n",
        "            'chin_displacement_output': 'binary_crossentropy'\n",
        "        },\n",
        "        metrics={\n",
        "            'real_fake_output': 'accuracy',\n",
        "            'pixelation_output': 'accuracy',\n",
        "            'shadow_output': 'accuracy',\n",
        "            'eye_asymmetry_output': 'accuracy',\n",
        "            'mouth_skewness_output': 'accuracy',\n",
        "            'nose_deviation_output': 'accuracy',\n",
        "            'chin_displacement_output': 'accuracy'\n",
        "        }\n",
        "    )\n",
        "\n",
        "    return model\n",
        "\n",
        "# Create the model\n",
        "model = create_multi_error_detection_model()\n"
      ],
      "metadata": {
        "id": "TO2K2nrGmBFQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Parameters\n",
        "batch_size = 32\n",
        "img_size = (128, 128)\n",
        "epochs = 10\n",
        "\n",
        "# Create the DataFrame generator\n",
        "train_generator = DataFrameGenerator(df, batch_size, img_size)\n",
        "\n",
        "model.summary()\n",
        "\n",
        "# Train the model\n",
        "model.fit(train_generator, epochs=epochs)\n"
      ],
      "metadata": {
        "id": "dunw67mlmWh0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "ac14f786-a2ce-4251-cea3-158369a3bd41"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"functional\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)             \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m       Param #\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mConnected to          \u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
              "│ input_layer (\u001b[38;5;33mInputLayer\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m3\u001b[0m)    │              \u001b[38;5;34m0\u001b[0m │ -                      │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ conv2d (\u001b[38;5;33mConv2D\u001b[0m)           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m126\u001b[0m, \u001b[38;5;34m126\u001b[0m, \u001b[38;5;34m32\u001b[0m)   │            \u001b[38;5;34m896\u001b[0m │ input_layer[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]      │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ max_pooling2d             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m63\u001b[0m, \u001b[38;5;34m63\u001b[0m, \u001b[38;5;34m32\u001b[0m)     │              \u001b[38;5;34m0\u001b[0m │ conv2d[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]           │\n",
              "│ (\u001b[38;5;33mMaxPooling2D\u001b[0m)            │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ conv2d_1 (\u001b[38;5;33mConv2D\u001b[0m)         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m61\u001b[0m, \u001b[38;5;34m61\u001b[0m, \u001b[38;5;34m64\u001b[0m)     │         \u001b[38;5;34m18,496\u001b[0m │ max_pooling2d[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ max_pooling2d_1           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m30\u001b[0m, \u001b[38;5;34m30\u001b[0m, \u001b[38;5;34m64\u001b[0m)     │              \u001b[38;5;34m0\u001b[0m │ conv2d_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]         │\n",
              "│ (\u001b[38;5;33mMaxPooling2D\u001b[0m)            │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ conv2d_2 (\u001b[38;5;33mConv2D\u001b[0m)         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m28\u001b[0m, \u001b[38;5;34m28\u001b[0m, \u001b[38;5;34m128\u001b[0m)    │         \u001b[38;5;34m73,856\u001b[0m │ max_pooling2d_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]  │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ max_pooling2d_2           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m128\u001b[0m)    │              \u001b[38;5;34m0\u001b[0m │ conv2d_2[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]         │\n",
              "│ (\u001b[38;5;33mMaxPooling2D\u001b[0m)            │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ flatten (\u001b[38;5;33mFlatten\u001b[0m)         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m25088\u001b[0m)          │              \u001b[38;5;34m0\u001b[0m │ max_pooling2d_2[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]  │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ dense (\u001b[38;5;33mDense\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │      \u001b[38;5;34m3,211,392\u001b[0m │ flatten[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]          │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ dropout (\u001b[38;5;33mDropout\u001b[0m)         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │              \u001b[38;5;34m0\u001b[0m │ dense[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]            │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ real_fake_output (\u001b[38;5;33mDense\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)              │            \u001b[38;5;34m129\u001b[0m │ dropout[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]          │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ pixelation_output (\u001b[38;5;33mDense\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)              │            \u001b[38;5;34m129\u001b[0m │ dropout[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]          │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ shadow_output (\u001b[38;5;33mDense\u001b[0m)     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)              │            \u001b[38;5;34m129\u001b[0m │ dropout[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]          │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ eye_asymmetry_output      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)              │            \u001b[38;5;34m129\u001b[0m │ dropout[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]          │\n",
              "│ (\u001b[38;5;33mDense\u001b[0m)                   │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ mouth_skewness_output     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)              │            \u001b[38;5;34m129\u001b[0m │ dropout[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]          │\n",
              "│ (\u001b[38;5;33mDense\u001b[0m)                   │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ nose_deviation_output     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)              │            \u001b[38;5;34m129\u001b[0m │ dropout[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]          │\n",
              "│ (\u001b[38;5;33mDense\u001b[0m)                   │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ chin_displacement_output  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)              │            \u001b[38;5;34m129\u001b[0m │ dropout[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]          │\n",
              "│ (\u001b[38;5;33mDense\u001b[0m)                   │                        │                │                        │\n",
              "└───────────────────────────┴────────────────────────┴────────────────┴────────────────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)              </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">        Param # </span>┃<span style=\"font-weight: bold\"> Connected to           </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
              "│ input_layer (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>)    │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                      │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ conv2d (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">126</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">126</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)   │            <span style=\"color: #00af00; text-decoration-color: #00af00\">896</span> │ input_layer[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]      │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ max_pooling2d             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">63</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">63</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)     │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ conv2d[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]           │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)            │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ conv2d_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">61</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">61</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)     │         <span style=\"color: #00af00; text-decoration-color: #00af00\">18,496</span> │ max_pooling2d[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ max_pooling2d_1           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">30</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">30</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)     │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ conv2d_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]         │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)            │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ conv2d_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)    │         <span style=\"color: #00af00; text-decoration-color: #00af00\">73,856</span> │ max_pooling2d_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]  │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ max_pooling2d_2           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)    │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ conv2d_2[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]         │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)            │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ flatten (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>)         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">25088</span>)          │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ max_pooling2d_2[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]  │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │      <span style=\"color: #00af00; text-decoration-color: #00af00\">3,211,392</span> │ flatten[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]          │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ dropout (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ dense[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]            │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ real_fake_output (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)              │            <span style=\"color: #00af00; text-decoration-color: #00af00\">129</span> │ dropout[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]          │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ pixelation_output (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)              │            <span style=\"color: #00af00; text-decoration-color: #00af00\">129</span> │ dropout[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]          │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ shadow_output (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)              │            <span style=\"color: #00af00; text-decoration-color: #00af00\">129</span> │ dropout[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]          │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ eye_asymmetry_output      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)              │            <span style=\"color: #00af00; text-decoration-color: #00af00\">129</span> │ dropout[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]          │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                   │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ mouth_skewness_output     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)              │            <span style=\"color: #00af00; text-decoration-color: #00af00\">129</span> │ dropout[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]          │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                   │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ nose_deviation_output     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)              │            <span style=\"color: #00af00; text-decoration-color: #00af00\">129</span> │ dropout[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]          │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                   │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ chin_displacement_output  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)              │            <span style=\"color: #00af00; text-decoration-color: #00af00\">129</span> │ dropout[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]          │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                   │                        │                │                        │\n",
              "└───────────────────────────┴────────────────────────┴────────────────┴────────────────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m3,305,543\u001b[0m (12.61 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">3,305,543</span> (12.61 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m3,305,543\u001b[0m (12.61 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">3,305,543</span> (12.61 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/trainers/data_adapters/py_dataset_adapter.py:121: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
            "  self._warn_if_super_not_called()\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m71s\u001b[0m 1s/step - chin_displacement_output_accuracy: 0.8721 - eye_asymmetry_output_accuracy: 0.5525 - loss: 3.2684 - mouth_skewness_output_accuracy: 0.5332 - nose_deviation_output_accuracy: 0.9355 - pixelation_output_accuracy: 0.9704 - real_fake_output_accuracy: 0.5872 - shadow_output_accuracy: 0.8807\n",
            "Epoch 2/10\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m77s\u001b[0m 1s/step - chin_displacement_output_accuracy: 0.9457 - eye_asymmetry_output_accuracy: 0.5874 - loss: 2.8005 - mouth_skewness_output_accuracy: 0.5218 - nose_deviation_output_accuracy: 0.9361 - pixelation_output_accuracy: 0.9723 - real_fake_output_accuracy: 0.5957 - shadow_output_accuracy: 0.9933\n",
            "Epoch 3/10\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m84s\u001b[0m 1s/step - chin_displacement_output_accuracy: 0.9468 - eye_asymmetry_output_accuracy: 0.6607 - loss: 2.6124 - mouth_skewness_output_accuracy: 0.5080 - nose_deviation_output_accuracy: 0.9335 - pixelation_output_accuracy: 0.9738 - real_fake_output_accuracy: 0.6669 - shadow_output_accuracy: 0.9937\n",
            "Epoch 4/10\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m79s\u001b[0m 1s/step - chin_displacement_output_accuracy: 0.9480 - eye_asymmetry_output_accuracy: 0.6467 - loss: 2.4431 - mouth_skewness_output_accuracy: 0.6161 - nose_deviation_output_accuracy: 0.9387 - pixelation_output_accuracy: 0.9835 - real_fake_output_accuracy: 0.6618 - shadow_output_accuracy: 0.9900\n",
            "Epoch 5/10\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m83s\u001b[0m 1s/step - chin_displacement_output_accuracy: 0.9463 - eye_asymmetry_output_accuracy: 0.6647 - loss: 2.2633 - mouth_skewness_output_accuracy: 0.6295 - nose_deviation_output_accuracy: 0.9377 - pixelation_output_accuracy: 0.9810 - real_fake_output_accuracy: 0.7121 - shadow_output_accuracy: 0.9941\n",
            "Epoch 6/10\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m80s\u001b[0m 1s/step - chin_displacement_output_accuracy: 0.9481 - eye_asymmetry_output_accuracy: 0.7204 - loss: 2.1343 - mouth_skewness_output_accuracy: 0.6880 - nose_deviation_output_accuracy: 0.9299 - pixelation_output_accuracy: 0.9859 - real_fake_output_accuracy: 0.7404 - shadow_output_accuracy: 0.9926\n",
            "Epoch 7/10\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m58s\u001b[0m 1s/step - chin_displacement_output_accuracy: 0.9391 - eye_asymmetry_output_accuracy: 0.7173 - loss: 2.0478 - mouth_skewness_output_accuracy: 0.7213 - nose_deviation_output_accuracy: 0.9278 - pixelation_output_accuracy: 0.9890 - real_fake_output_accuracy: 0.7587 - shadow_output_accuracy: 0.9908\n",
            "Epoch 8/10\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m56s\u001b[0m 1s/step - chin_displacement_output_accuracy: 0.9498 - eye_asymmetry_output_accuracy: 0.7450 - loss: 1.8369 - mouth_skewness_output_accuracy: 0.7524 - nose_deviation_output_accuracy: 0.9393 - pixelation_output_accuracy: 0.9814 - real_fake_output_accuracy: 0.7822 - shadow_output_accuracy: 0.9919\n",
            "Epoch 9/10\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m65s\u001b[0m 2s/step - chin_displacement_output_accuracy: 0.9478 - eye_asymmetry_output_accuracy: 0.7517 - loss: 1.7477 - mouth_skewness_output_accuracy: 0.7655 - nose_deviation_output_accuracy: 0.9433 - pixelation_output_accuracy: 0.9846 - real_fake_output_accuracy: 0.7903 - shadow_output_accuracy: 0.9947\n",
            "Epoch 10/10\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m75s\u001b[0m 1s/step - chin_displacement_output_accuracy: 0.9522 - eye_asymmetry_output_accuracy: 0.7621 - loss: 1.6974 - mouth_skewness_output_accuracy: 0.7674 - nose_deviation_output_accuracy: 0.9496 - pixelation_output_accuracy: 0.9853 - real_fake_output_accuracy: 0.7706 - shadow_output_accuracy: 0.9912\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.history.History at 0x7c93d9dd9a20>"
            ]
          },
          "metadata": {},
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def predict_image(model, image_path):\n",
        "    img = load_img(image_path, target_size=(128, 128))\n",
        "    img_array = img_to_array(img)\n",
        "    img_array = np.expand_dims(img_array, axis=0)\n",
        "    img_array = img_array / 255.0  # Normalize the image\n",
        "\n",
        "    predictions = model.predict(img_array)\n",
        "\n",
        "    real_fake_prob = predictions[0][0]\n",
        "    pixelation_prob = predictions[1][0]\n",
        "    shadow_prob = predictions[2][0]\n",
        "    nose_deviation_prob = predictions[3][0]\n",
        "    chin_displacement_prob = predictions[4][0]\n",
        "\n",
        "    # Determine Real/Fake label\n",
        "    real_fake_label = 'Real' if real_fake_prob > 0.5 else 'Fake'\n",
        "    real_fake_confidence = real_fake_prob if real_fake_prob > 0.5 else 1 - real_fake_prob\n",
        "\n",
        "    # Error probabilities\n",
        "    error_probabilities = {\n",
        "        'Pixelation': pixelation_prob * 100,\n",
        "        'Shadow Inconsistency': shadow_prob * 100,\n",
        "        'Eye Asymmetry': 100 - (pixelation_prob + shadow_prob) * 100,\n",
        "        'Mouth Skewness': 100 - (pixelation_prob + shadow_prob) * 100,\n",
        "        'Nose Deviation': nose_deviation_prob * 100,\n",
        "        'Chin Displacement': chin_displacement_prob * 100\n",
        "    }\n",
        "\n",
        "    return real_fake_label, real_fake_confidence * 100, error_probabilities\n"
      ],
      "metadata": {
        "id": "K20TkM7hmcz9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Predict on a sample image\n",
        "real_fake_ratio = []\n",
        "for img_meta in f_imgs:\n",
        "   image_path = img_meta['filepath']\n",
        "   real_fake_label, real_fake_confidence, error_probabilities = predict_image(model, image_path)\n",
        "   real_fake_confidence = real_fake_confidence.item()\n",
        "   real_fake_ratio.append(real_fake_label)\n",
        "   print(f\"Label: {real_fake_label}, Confidence: {real_fake_confidence:.2f}%\")\n",
        "   print(\"Error Probabilities:\", error_probabilities)\n",
        "print(real_fake_ratio)"
      ],
      "metadata": {
        "id": "x-9Pu_4jgoFz",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a71ab711-db5f-4f98-e524-083e30abfc61"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 184ms/step\n",
            "Label: Real, Confidence: 62.24%\n",
            "Error Probabilities: {'Pixelation': array([99.91405], dtype=float32), 'Shadow Inconsistency': array([0.19404912], dtype=float32), 'Eye Asymmetry': array([-0.10810089], dtype=float32), 'Mouth Skewness': array([-0.10810089], dtype=float32), 'Nose Deviation': array([47.561417], dtype=float32), 'Chin Displacement': array([12.929704], dtype=float32)}\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step\n",
            "Label: Real, Confidence: 82.39%\n",
            "Error Probabilities: {'Pixelation': array([99.80105], dtype=float32), 'Shadow Inconsistency': array([0.20560767], dtype=float32), 'Eye Asymmetry': array([-0.00666046], dtype=float32), 'Mouth Skewness': array([-0.00666046], dtype=float32), 'Nose Deviation': array([56.3854], dtype=float32), 'Chin Displacement': array([36.683697], dtype=float32)}\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step\n",
            "Label: Real, Confidence: 80.56%\n",
            "Error Probabilities: {'Pixelation': array([99.944336], dtype=float32), 'Shadow Inconsistency': array([0.10413101], dtype=float32), 'Eye Asymmetry': array([-0.04846954], dtype=float32), 'Mouth Skewness': array([-0.04846954], dtype=float32), 'Nose Deviation': array([74.23233], dtype=float32), 'Chin Displacement': array([23.768646], dtype=float32)}\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step\n",
            "Label: Real, Confidence: 72.76%\n",
            "Error Probabilities: {'Pixelation': array([99.59653], dtype=float32), 'Shadow Inconsistency': array([0.54005754], dtype=float32), 'Eye Asymmetry': array([-0.13658905], dtype=float32), 'Mouth Skewness': array([-0.13658905], dtype=float32), 'Nose Deviation': array([41.50068], dtype=float32), 'Chin Displacement': array([14.743443], dtype=float32)}\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step\n",
            "Label: Real, Confidence: 62.14%\n",
            "Error Probabilities: {'Pixelation': array([99.96974], dtype=float32), 'Shadow Inconsistency': array([0.03338788], dtype=float32), 'Eye Asymmetry': array([-0.00312042], dtype=float32), 'Mouth Skewness': array([-0.00312042], dtype=float32), 'Nose Deviation': array([53.217804], dtype=float32), 'Chin Displacement': array([18.299324], dtype=float32)}\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step\n",
            "Label: Real, Confidence: 64.58%\n",
            "Error Probabilities: {'Pixelation': array([99.94425], dtype=float32), 'Shadow Inconsistency': array([0.03416004], dtype=float32), 'Eye Asymmetry': array([0.02159119], dtype=float32), 'Mouth Skewness': array([0.02159119], dtype=float32), 'Nose Deviation': array([66.089836], dtype=float32), 'Chin Displacement': array([23.493143], dtype=float32)}\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step\n",
            "Label: Real, Confidence: 79.73%\n",
            "Error Probabilities: {'Pixelation': array([99.95646], dtype=float32), 'Shadow Inconsistency': array([0.08428832], dtype=float32), 'Eye Asymmetry': array([-0.0407486], dtype=float32), 'Mouth Skewness': array([-0.0407486], dtype=float32), 'Nose Deviation': array([80.05522], dtype=float32), 'Chin Displacement': array([27.812], dtype=float32)}\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step\n",
            "Label: Real, Confidence: 78.27%\n",
            "Error Probabilities: {'Pixelation': array([99.39325], dtype=float32), 'Shadow Inconsistency': array([1.3596628], dtype=float32), 'Eye Asymmetry': array([-0.7529144], dtype=float32), 'Mouth Skewness': array([-0.7529144], dtype=float32), 'Nose Deviation': array([50.607483], dtype=float32), 'Chin Displacement': array([21.531534], dtype=float32)}\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step\n",
            "Label: Real, Confidence: 71.14%\n",
            "Error Probabilities: {'Pixelation': array([99.8751], dtype=float32), 'Shadow Inconsistency': array([0.08374095], dtype=float32), 'Eye Asymmetry': array([0.04116058], dtype=float32), 'Mouth Skewness': array([0.04116058], dtype=float32), 'Nose Deviation': array([55.69208], dtype=float32), 'Chin Displacement': array([12.940286], dtype=float32)}\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step\n",
            "Label: Real, Confidence: 77.41%\n",
            "Error Probabilities: {'Pixelation': array([99.983376], dtype=float32), 'Shadow Inconsistency': array([0.04527971], dtype=float32), 'Eye Asymmetry': array([-0.02865601], dtype=float32), 'Mouth Skewness': array([-0.02865601], dtype=float32), 'Nose Deviation': array([48.98668], dtype=float32), 'Chin Displacement': array([9.240691], dtype=float32)}\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step\n",
            "Label: Real, Confidence: 56.86%\n",
            "Error Probabilities: {'Pixelation': array([99.951935], dtype=float32), 'Shadow Inconsistency': array([0.02888247], dtype=float32), 'Eye Asymmetry': array([0.0191803], dtype=float32), 'Mouth Skewness': array([0.0191803], dtype=float32), 'Nose Deviation': array([53.950645], dtype=float32), 'Chin Displacement': array([13.937284], dtype=float32)}\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step\n",
            "Label: Real, Confidence: 81.10%\n",
            "Error Probabilities: {'Pixelation': array([99.93893], dtype=float32), 'Shadow Inconsistency': array([0.05929735], dtype=float32), 'Eye Asymmetry': array([0.00178528], dtype=float32), 'Mouth Skewness': array([0.00178528], dtype=float32), 'Nose Deviation': array([51.615326], dtype=float32), 'Chin Displacement': array([14.843698], dtype=float32)}\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 53ms/step\n",
            "Label: Real, Confidence: 60.93%\n",
            "Error Probabilities: {'Pixelation': array([99.78787], dtype=float32), 'Shadow Inconsistency': array([0.14816166], dtype=float32), 'Eye Asymmetry': array([0.06396484], dtype=float32), 'Mouth Skewness': array([0.06396484], dtype=float32), 'Nose Deviation': array([42.51021], dtype=float32), 'Chin Displacement': array([9.32461], dtype=float32)}\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step\n",
            "Label: Real, Confidence: 89.22%\n",
            "Error Probabilities: {'Pixelation': array([99.896935], dtype=float32), 'Shadow Inconsistency': array([0.80206776], dtype=float32), 'Eye Asymmetry': array([-0.6989975], dtype=float32), 'Mouth Skewness': array([-0.6989975], dtype=float32), 'Nose Deviation': array([57.350246], dtype=float32), 'Chin Displacement': array([16.052544], dtype=float32)}\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step\n",
            "Label: Real, Confidence: 74.44%\n",
            "Error Probabilities: {'Pixelation': array([99.979576], dtype=float32), 'Shadow Inconsistency': array([0.03329593], dtype=float32), 'Eye Asymmetry': array([-0.01287842], dtype=float32), 'Mouth Skewness': array([-0.01287842], dtype=float32), 'Nose Deviation': array([49.36161], dtype=float32), 'Chin Displacement': array([8.898684], dtype=float32)}\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step\n",
            "Label: Real, Confidence: 57.46%\n",
            "Error Probabilities: {'Pixelation': array([99.99497], dtype=float32), 'Shadow Inconsistency': array([0.01196665], dtype=float32), 'Eye Asymmetry': array([-0.00693512], dtype=float32), 'Mouth Skewness': array([-0.00693512], dtype=float32), 'Nose Deviation': array([26.262072], dtype=float32), 'Chin Displacement': array([1.9777596], dtype=float32)}\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step\n",
            "Label: Fake, Confidence: 63.20%\n",
            "Error Probabilities: {'Pixelation': array([99.94236], dtype=float32), 'Shadow Inconsistency': array([0.04336679], dtype=float32), 'Eye Asymmetry': array([0.0142746], dtype=float32), 'Mouth Skewness': array([0.0142746], dtype=float32), 'Nose Deviation': array([46.579376], dtype=float32), 'Chin Displacement': array([5.6405487], dtype=float32)}\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step\n",
            "Label: Real, Confidence: 64.44%\n",
            "Error Probabilities: {'Pixelation': array([99.977356], dtype=float32), 'Shadow Inconsistency': array([0.02046446], dtype=float32), 'Eye Asymmetry': array([0.00218201], dtype=float32), 'Mouth Skewness': array([0.00218201], dtype=float32), 'Nose Deviation': array([68.90565], dtype=float32), 'Chin Displacement': array([8.606796], dtype=float32)}\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step\n",
            "Label: Real, Confidence: 63.60%\n",
            "Error Probabilities: {'Pixelation': array([99.985466], dtype=float32), 'Shadow Inconsistency': array([0.01205361], dtype=float32), 'Eye Asymmetry': array([0.00248718], dtype=float32), 'Mouth Skewness': array([0.00248718], dtype=float32), 'Nose Deviation': array([25.45757], dtype=float32), 'Chin Displacement': array([1.8553336], dtype=float32)}\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step\n",
            "Label: Real, Confidence: 64.16%\n",
            "Error Probabilities: {'Pixelation': array([99.99477], dtype=float32), 'Shadow Inconsistency': array([0.01001792], dtype=float32), 'Eye Asymmetry': array([-0.00478363], dtype=float32), 'Mouth Skewness': array([-0.00478363], dtype=float32), 'Nose Deviation': array([35.019474], dtype=float32), 'Chin Displacement': array([2.7216642], dtype=float32)}\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step\n",
            "Label: Real, Confidence: 88.10%\n",
            "Error Probabilities: {'Pixelation': array([99.95795], dtype=float32), 'Shadow Inconsistency': array([0.13537394], dtype=float32), 'Eye Asymmetry': array([-0.09331512], dtype=float32), 'Mouth Skewness': array([-0.09331512], dtype=float32), 'Nose Deviation': array([45.95081], dtype=float32), 'Chin Displacement': array([15.4071245], dtype=float32)}\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step\n",
            "Label: Fake, Confidence: 55.47%\n",
            "Error Probabilities: {'Pixelation': array([99.986496], dtype=float32), 'Shadow Inconsistency': array([0.00727572], dtype=float32), 'Eye Asymmetry': array([0.00622559], dtype=float32), 'Mouth Skewness': array([0.00622559], dtype=float32), 'Nose Deviation': array([85.32069], dtype=float32), 'Chin Displacement': array([19.697697], dtype=float32)}\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step\n",
            "Label: Real, Confidence: 81.97%\n",
            "Error Probabilities: {'Pixelation': array([99.968994], dtype=float32), 'Shadow Inconsistency': array([0.04359795], dtype=float32), 'Eye Asymmetry': array([-0.0125885], dtype=float32), 'Mouth Skewness': array([-0.0125885], dtype=float32), 'Nose Deviation': array([39.512787], dtype=float32), 'Chin Displacement': array([9.000998], dtype=float32)}\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step\n",
            "Label: Real, Confidence: 81.14%\n",
            "Error Probabilities: {'Pixelation': array([99.78687], dtype=float32), 'Shadow Inconsistency': array([0.49067187], dtype=float32), 'Eye Asymmetry': array([-0.2775421], dtype=float32), 'Mouth Skewness': array([-0.2775421], dtype=float32), 'Nose Deviation': array([58.361626], dtype=float32), 'Chin Displacement': array([25.66967], dtype=float32)}\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step\n",
            "Label: Real, Confidence: 83.42%\n",
            "Error Probabilities: {'Pixelation': array([99.82854], dtype=float32), 'Shadow Inconsistency': array([0.43239692], dtype=float32), 'Eye Asymmetry': array([-0.26094055], dtype=float32), 'Mouth Skewness': array([-0.26094055], dtype=float32), 'Nose Deviation': array([74.93297], dtype=float32), 'Chin Displacement': array([43.84238], dtype=float32)}\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step\n",
            "Label: Real, Confidence: 74.48%\n",
            "Error Probabilities: {'Pixelation': array([98.69255], dtype=float32), 'Shadow Inconsistency': array([2.4224343], dtype=float32), 'Eye Asymmetry': array([-1.1149902], dtype=float32), 'Mouth Skewness': array([-1.1149902], dtype=float32), 'Nose Deviation': array([64.05354], dtype=float32), 'Chin Displacement': array([49.43096], dtype=float32)}\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step\n",
            "Label: Real, Confidence: 70.41%\n",
            "Error Probabilities: {'Pixelation': array([99.992424], dtype=float32), 'Shadow Inconsistency': array([0.04102225], dtype=float32), 'Eye Asymmetry': array([-0.03344727], dtype=float32), 'Mouth Skewness': array([-0.03344727], dtype=float32), 'Nose Deviation': array([48.425465], dtype=float32), 'Chin Displacement': array([5.050739], dtype=float32)}\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step\n",
            "Label: Real, Confidence: 75.83%\n",
            "Error Probabilities: {'Pixelation': array([99.880745], dtype=float32), 'Shadow Inconsistency': array([0.11291433], dtype=float32), 'Eye Asymmetry': array([0.00634003], dtype=float32), 'Mouth Skewness': array([0.00634003], dtype=float32), 'Nose Deviation': array([50.307297], dtype=float32), 'Chin Displacement': array([21.327154], dtype=float32)}\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step\n",
            "Label: Real, Confidence: 65.27%\n",
            "Error Probabilities: {'Pixelation': array([99.73083], dtype=float32), 'Shadow Inconsistency': array([0.221513], dtype=float32), 'Eye Asymmetry': array([0.04766083], dtype=float32), 'Mouth Skewness': array([0.04766083], dtype=float32), 'Nose Deviation': array([45.09007], dtype=float32), 'Chin Displacement': array([9.875217], dtype=float32)}\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step\n",
            "Label: Real, Confidence: 77.84%\n",
            "Error Probabilities: {'Pixelation': array([99.98496], dtype=float32), 'Shadow Inconsistency': array([0.05998608], dtype=float32), 'Eye Asymmetry': array([-0.04494476], dtype=float32), 'Mouth Skewness': array([-0.04494476], dtype=float32), 'Nose Deviation': array([86.96953], dtype=float32), 'Chin Displacement': array([44.366898], dtype=float32)}\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step\n",
            "Label: Fake, Confidence: 63.64%\n",
            "Error Probabilities: {'Pixelation': array([99.95903], dtype=float32), 'Shadow Inconsistency': array([0.01372189], dtype=float32), 'Eye Asymmetry': array([0.02724457], dtype=float32), 'Mouth Skewness': array([0.02724457], dtype=float32), 'Nose Deviation': array([61.913532], dtype=float32), 'Chin Displacement': array([15.483721], dtype=float32)}\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step\n",
            "Label: Fake, Confidence: 52.22%\n",
            "Error Probabilities: {'Pixelation': array([99.619064], dtype=float32), 'Shadow Inconsistency': array([0.26203614], dtype=float32), 'Eye Asymmetry': array([0.11890411], dtype=float32), 'Mouth Skewness': array([0.11890411], dtype=float32), 'Nose Deviation': array([32.135746], dtype=float32), 'Chin Displacement': array([8.259308], dtype=float32)}\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step\n",
            "Label: Real, Confidence: 73.73%\n",
            "Error Probabilities: {'Pixelation': array([99.99002], dtype=float32), 'Shadow Inconsistency': array([0.02293142], dtype=float32), 'Eye Asymmetry': array([-0.01295471], dtype=float32), 'Mouth Skewness': array([-0.01295471], dtype=float32), 'Nose Deviation': array([82.90643], dtype=float32), 'Chin Displacement': array([23.947086], dtype=float32)}\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step\n",
            "Label: Real, Confidence: 89.08%\n",
            "Error Probabilities: {'Pixelation': array([99.95842], dtype=float32), 'Shadow Inconsistency': array([0.18857843], dtype=float32), 'Eye Asymmetry': array([-0.14699554], dtype=float32), 'Mouth Skewness': array([-0.14699554], dtype=float32), 'Nose Deviation': array([58.4782], dtype=float32), 'Chin Displacement': array([24.567095], dtype=float32)}\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step\n",
            "Label: Real, Confidence: 64.77%\n",
            "Error Probabilities: {'Pixelation': array([99.93576], dtype=float32), 'Shadow Inconsistency': array([0.04714318], dtype=float32), 'Eye Asymmetry': array([0.01709747], dtype=float32), 'Mouth Skewness': array([0.01709747], dtype=float32), 'Nose Deviation': array([58.445568], dtype=float32), 'Chin Displacement': array([17.045494], dtype=float32)}\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step\n",
            "Label: Fake, Confidence: 52.20%\n",
            "Error Probabilities: {'Pixelation': array([99.9853], dtype=float32), 'Shadow Inconsistency': array([0.01019766], dtype=float32), 'Eye Asymmetry': array([0.00450897], dtype=float32), 'Mouth Skewness': array([0.00450897], dtype=float32), 'Nose Deviation': array([84.57182], dtype=float32), 'Chin Displacement': array([19.163528], dtype=float32)}\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step\n",
            "Label: Real, Confidence: 73.14%\n",
            "Error Probabilities: {'Pixelation': array([99.9309], dtype=float32), 'Shadow Inconsistency': array([0.12706196], dtype=float32), 'Eye Asymmetry': array([-0.05796051], dtype=float32), 'Mouth Skewness': array([-0.05796051], dtype=float32), 'Nose Deviation': array([74.63126], dtype=float32), 'Chin Displacement': array([28.988281], dtype=float32)}\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step\n",
            "Label: Real, Confidence: 51.48%\n",
            "Error Probabilities: {'Pixelation': array([99.98333], dtype=float32), 'Shadow Inconsistency': array([0.03982234], dtype=float32), 'Eye Asymmetry': array([-0.02314758], dtype=float32), 'Mouth Skewness': array([-0.02314758], dtype=float32), 'Nose Deviation': array([62.245514], dtype=float32), 'Chin Displacement': array([13.135142], dtype=float32)}\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step\n",
            "Label: Real, Confidence: 75.88%\n",
            "Error Probabilities: {'Pixelation': array([99.73476], dtype=float32), 'Shadow Inconsistency': array([0.33399263], dtype=float32), 'Eye Asymmetry': array([-0.06874847], dtype=float32), 'Mouth Skewness': array([-0.06874847], dtype=float32), 'Nose Deviation': array([53.35984], dtype=float32), 'Chin Displacement': array([19.771677], dtype=float32)}\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step\n",
            "Label: Real, Confidence: 80.68%\n",
            "Error Probabilities: {'Pixelation': array([99.98247], dtype=float32), 'Shadow Inconsistency': array([0.03096965], dtype=float32), 'Eye Asymmetry': array([-0.01343536], dtype=float32), 'Mouth Skewness': array([-0.01343536], dtype=float32), 'Nose Deviation': array([44.73213], dtype=float32), 'Chin Displacement': array([5.3242865], dtype=float32)}\n",
            "['Real', 'Real', 'Real', 'Real', 'Real', 'Real', 'Real', 'Real', 'Real', 'Real', 'Real', 'Real', 'Real', 'Real', 'Real', 'Real', 'Fake', 'Real', 'Real', 'Real', 'Real', 'Fake', 'Real', 'Real', 'Real', 'Real', 'Real', 'Real', 'Real', 'Real', 'Fake', 'Fake', 'Real', 'Real', 'Real', 'Fake', 'Real', 'Real', 'Real', 'Real']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "real_c = 0\n",
        "fake_c = 0\n",
        "for i in real_fake_ratio:\n",
        "  if(i=='Real'):\n",
        "    real_c+=1\n",
        "  else:\n",
        "    fake_c+=1\n",
        "print(\"real persentage : \",real_c/len(real_fake_ratio) * 100)\n",
        "print(\"fake persentage : \",fake_c/len(real_fake_ratio) * 100)"
      ],
      "metadata": {
        "id": "qC6U1NAKO_iX",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d11ae973-45e0-4fd3-815a-c303479d7ac3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "real persentage :  87.5\n",
            "fake persentage :  12.5\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pickle\n",
        "\n",
        "# Load the .pkl model\n",
        "with open('/content/drive/MyDrive/model.pkl', 'rb') as file:\n",
        "    model = pickle.load(file)"
      ],
      "metadata": {
        "id": "sgw8nFDfEhT1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.models import save_model\n",
        "\n",
        "# Save the model in .h5 format\n",
        "model.save('/content/drive/MyDrive/model.h5')  # Save it as .h5 format\n",
        "\n",
        "# Alternatively, save in .keras format\n",
        "model.save('/content/drive/MyDrive/model.keras')  # Save it as .keras format"
      ],
      "metadata": {
        "id": "2rlTDjnTwCXZ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4aa6d728-f37f-4c86-dd3c-459c5cefc943"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install flask-ngrok\n",
        "!pip install flask\n",
        "!pip install dlib\n",
        "!pip install tensorflow\n",
        "!pip install pillow\n",
        "!apt-get install cmake\n",
        "!pip install face_recognition\n",
        "!pip install opencv-python-headless"
      ],
      "metadata": {
        "id": "vBNx4iWIuxoM",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cc199b02-4591-4113-f3ad-44bb79c8e66f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting flask-ngrok\n",
            "  Downloading flask_ngrok-0.0.25-py3-none-any.whl.metadata (1.8 kB)\n",
            "Requirement already satisfied: Flask>=0.8 in /usr/local/lib/python3.10/dist-packages (from flask-ngrok) (2.2.5)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from flask-ngrok) (2.32.3)\n",
            "Requirement already satisfied: Werkzeug>=2.2.2 in /usr/local/lib/python3.10/dist-packages (from Flask>=0.8->flask-ngrok) (3.0.4)\n",
            "Requirement already satisfied: Jinja2>=3.0 in /usr/local/lib/python3.10/dist-packages (from Flask>=0.8->flask-ngrok) (3.1.4)\n",
            "Requirement already satisfied: itsdangerous>=2.0 in /usr/local/lib/python3.10/dist-packages (from Flask>=0.8->flask-ngrok) (2.2.0)\n",
            "Requirement already satisfied: click>=8.0 in /usr/local/lib/python3.10/dist-packages (from Flask>=0.8->flask-ngrok) (8.1.7)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->flask-ngrok) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->flask-ngrok) (3.8)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->flask-ngrok) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->flask-ngrok) (2024.7.4)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from Jinja2>=3.0->Flask>=0.8->flask-ngrok) (2.1.5)\n",
            "Downloading flask_ngrok-0.0.25-py3-none-any.whl (3.1 kB)\n",
            "Installing collected packages: flask-ngrok\n",
            "Successfully installed flask-ngrok-0.0.25\n",
            "Requirement already satisfied: flask in /usr/local/lib/python3.10/dist-packages (2.2.5)\n",
            "Requirement already satisfied: Werkzeug>=2.2.2 in /usr/local/lib/python3.10/dist-packages (from flask) (3.0.4)\n",
            "Requirement already satisfied: Jinja2>=3.0 in /usr/local/lib/python3.10/dist-packages (from flask) (3.1.4)\n",
            "Requirement already satisfied: itsdangerous>=2.0 in /usr/local/lib/python3.10/dist-packages (from flask) (2.2.0)\n",
            "Requirement already satisfied: click>=8.0 in /usr/local/lib/python3.10/dist-packages (from flask) (8.1.7)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from Jinja2>=3.0->flask) (2.1.5)\n",
            "Requirement already satisfied: dlib in /usr/local/lib/python3.10/dist-packages (19.24.2)\n",
            "Requirement already satisfied: tensorflow in /usr/local/lib/python3.10/dist-packages (2.17.0)\n",
            "Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.4.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.6.3)\n",
            "Requirement already satisfied: flatbuffers>=24.3.25 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (24.3.25)\n",
            "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.6.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.2.0)\n",
            "Requirement already satisfied: h5py>=3.10.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.11.0)\n",
            "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (18.1.1)\n",
            "Requirement already satisfied: ml-dtypes<0.5.0,>=0.3.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.4.0)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.3.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from tensorflow) (24.1)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.20.3)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.32.3)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from tensorflow) (71.0.4)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.16.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.4.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (4.12.2)\n",
            "Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.16.0)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.64.1)\n",
            "Requirement already satisfied: tensorboard<2.18,>=2.17 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.17.0)\n",
            "Requirement already satisfied: keras>=3.2.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.4.1)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.37.1)\n",
            "Requirement already satisfied: numpy<2.0.0,>=1.23.5 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.26.4)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from astunparse>=1.6.0->tensorflow) (0.44.0)\n",
            "Requirement already satisfied: rich in /usr/local/lib/python3.10/dist-packages (from keras>=3.2.0->tensorflow) (13.8.0)\n",
            "Requirement already satisfied: namex in /usr/local/lib/python3.10/dist-packages (from keras>=3.2.0->tensorflow) (0.0.8)\n",
            "Requirement already satisfied: optree in /usr/local/lib/python3.10/dist-packages (from keras>=3.2.0->tensorflow) (0.12.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorflow) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorflow) (3.8)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorflow) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorflow) (2024.7.4)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.18,>=2.17->tensorflow) (3.7)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.18,>=2.17->tensorflow) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.18,>=2.17->tensorflow) (3.0.4)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.10/dist-packages (from werkzeug>=1.0.1->tensorboard<2.18,>=2.17->tensorflow) (2.1.5)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich->keras>=3.2.0->tensorflow) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich->keras>=3.2.0->tensorflow) (2.16.1)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich->keras>=3.2.0->tensorflow) (0.1.2)\n",
            "Requirement already satisfied: pillow in /usr/local/lib/python3.10/dist-packages (9.4.0)\n",
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "cmake is already the newest version (3.22.1-1ubuntu1.22.04.2).\n",
            "0 upgraded, 0 newly installed, 0 to remove and 49 not upgraded.\n",
            "Collecting face_recognition\n",
            "  Downloading face_recognition-1.3.0-py2.py3-none-any.whl.metadata (21 kB)\n",
            "Collecting face-recognition-models>=0.3.0 (from face_recognition)\n",
            "  Downloading face_recognition_models-0.3.0.tar.gz (100.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m100.1/100.1 MB\u001b[0m \u001b[31m7.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: Click>=6.0 in /usr/local/lib/python3.10/dist-packages (from face_recognition) (8.1.7)\n",
            "Requirement already satisfied: dlib>=19.7 in /usr/local/lib/python3.10/dist-packages (from face_recognition) (19.24.2)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from face_recognition) (1.26.4)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.10/dist-packages (from face_recognition) (9.4.0)\n",
            "Downloading face_recognition-1.3.0-py2.py3-none-any.whl (15 kB)\n",
            "Building wheels for collected packages: face-recognition-models\n",
            "  Building wheel for face-recognition-models (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for face-recognition-models: filename=face_recognition_models-0.3.0-py2.py3-none-any.whl size=100566164 sha256=bcce2cd3b4d731822d841da81225fff999af76ca19c99270588f50699a905872\n",
            "  Stored in directory: /root/.cache/pip/wheels/7a/eb/cf/e9eced74122b679557f597bb7c8e4c739cfcac526db1fd523d\n",
            "Successfully built face-recognition-models\n",
            "Installing collected packages: face-recognition-models, face_recognition\n",
            "Successfully installed face-recognition-models-0.3.0 face_recognition-1.3.0\n",
            "Requirement already satisfied: opencv-python-headless in /usr/local/lib/python3.10/dist-packages (4.10.0.84)\n",
            "Requirement already satisfied: numpy>=1.21.2 in /usr/local/lib/python3.10/dist-packages (from opencv-python-headless) (1.26.4)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!apt-get install ngrok  # Install Ngrok\n",
        "!ngrok authtoken \"2lVh1lhns8BObYcyJgVN7F2QA7t_6MdTZ4u6dgyA3GDkee2L3\"\n",
        "!ngrok http 5000"
      ],
      "metadata": {
        "id": "3I4tzCmOxDAU",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7786baa0-2bd8-4d60-fce3-6b0c52d22134"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "E: Unable to locate package ngrok\n",
            "/bin/bash: line 1: ngrok: command not found\n",
            "/bin/bash: line 1: ngrok: command not found\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import shutil\n",
        "import cv2\n",
        "import dlib\n",
        "import numpy as np\n",
        "from PIL import Image\n",
        "from flask import Flask, request, redirect, jsonify\n",
        "from flask_ngrok import run_with_ngrok\n",
        "from tensorflow.keras.models import load_model\n",
        "from tensorflow.keras.preprocessing.image import load_img, img_to_array\n",
        "from pyngrok import ngrok\n",
        "\n",
        "app = Flask(__name__)\n",
        "run_with_ngrok(app)  # Start ngrok when the app is run\n",
        "\n",
        "# Load the pre-trained model\n",
        "model = load_model('/content/drive/MyDrive/model.keras')\n",
        "\n",
        "# Define directories for saving images\n",
        "img_file = \"Frame_img\"\n",
        "crop_image_file = \"crop_img\"\n",
        "\n",
        "if os.path.isdir(img_file):\n",
        "    shutil.rmtree(img_file)\n",
        "os.mkdir(img_file)\n",
        "\n",
        "if os.path.isdir(crop_image_file):\n",
        "    shutil.rmtree(crop_image_file)\n",
        "os.mkdir(crop_image_file)\n",
        "\n",
        "detector = dlib.get_frontal_face_detector()\n",
        "predictor = dlib.shape_predictor(\"shape_predictor_68_face_landmarks.dat\")\n",
        "\n",
        "def detect_and_crop_face_dlib(image_path, output_path):\n",
        "    img = dlib.load_rgb_image(image_path)\n",
        "    faces = detector(img, 1)\n",
        "\n",
        "    if len(faces) == 0:\n",
        "        return None\n",
        "\n",
        "    for face in faces:\n",
        "        x, y, w, h = face.left(), face.top(), face.width(), face.height()\n",
        "        cropped_face = Image.fromarray(img[y:y+h, x:x+w])\n",
        "        cropped_face.save(output_path)\n",
        "        return cropped_face\n",
        "\n",
        "def process_video(video_path):\n",
        "    capture = cv2.VideoCapture(video_path)\n",
        "    f = 0\n",
        "    intrval = 12\n",
        "    save_frame = 0\n",
        "    while capture.isOpened():\n",
        "        ret, frame = capture.read()\n",
        "        if not ret:\n",
        "            break\n",
        "        if f % intrval == 0:\n",
        "            cv2.imwrite(f'{img_file}/imgf{f}.jpg', frame)\n",
        "            save_frame += 1\n",
        "        f += 1\n",
        "\n",
        "    k = 0\n",
        "    for filename in os.listdir(img_file):\n",
        "        if filename.endswith('.jpg'):\n",
        "            detect_and_crop_face_dlib(f'{img_file}/{filename}', f'{crop_image_file}/frame-{k}.jpg')\n",
        "            k += 1\n",
        "\n",
        "def predict_image(model, image_path):\n",
        "    img = load_img(image_path, target_size=(128, 128))\n",
        "    img_array = img_to_array(img)\n",
        "    img_array = np.expand_dims(img_array, axis=0)\n",
        "    img_array = img_array / 255.0  # Normalize the image\n",
        "\n",
        "    predictions = model.predict(img_array)\n",
        "\n",
        "    # Convert predictions to scalar values\n",
        "    real_fake_prob = float(predictions[0][0])\n",
        "    pixelation_prob = float(predictions[1][0])\n",
        "    shadow_prob = float(predictions[2][0])\n",
        "    eye_asymmetry_prob = float(predictions[3][0])\n",
        "    mouth_skewness_prob = float(predictions[4][0])\n",
        "    nose_deviation_prob = float(predictions[5][0])\n",
        "    chin_displacement_prob = float(predictions[6][0])\n",
        "\n",
        "    real_fake_label = 'Real' if real_fake_prob > 0.5 else 'Fake'\n",
        "    real_fake_confidence = real_fake_prob if real_fake_prob > 0.5 else 1 - real_fake_prob\n",
        "\n",
        "    error_probabilities = {\n",
        "        'Pixelation': pixelation_prob * 100,\n",
        "        'Shadow Inconsistency': shadow_prob * 100,\n",
        "        'Eye Asymmetry': eye_asymmetry_prob * 100,\n",
        "        'Mouth Skewness': mouth_skewness_prob * 100,\n",
        "        'Nose Deviation': nose_deviation_prob * 100,\n",
        "        'Chin Displacement': chin_displacement_prob * 100\n",
        "    }\n",
        "\n",
        "    return real_fake_label, real_fake_confidence * 100, error_probabilities\n",
        "\n",
        "@app.route('/')\n",
        "def home():\n",
        "    return '''\n",
        "        <html lang=\"en\">\n",
        "<head>\n",
        "    <link rel=\"stylesheet\" type=\"text/css\" href=\"/static/styles.css\">\n",
        "    <script src=\"/static/scripts.js\"></script>\n",
        "</head>\n",
        "<body>\n",
        "    <div class=\"home\">\n",
        "        <h1>Upload a Video</h1>\n",
        "        <form action=\"/upload\" method=\"post\" enctype=\"multipart/form-data\">\n",
        "            <input type=\"file\" name=\"file\" accept=\"video/*\">\n",
        "            <input type=\"submit\" value=\"Upload\">\n",
        "        </form>\n",
        "    </div>\n",
        "</body>\n",
        "</html>\n",
        "    '''\n",
        "\n",
        "@app.route('/upload', methods=['POST'])\n",
        "def upload_file():\n",
        "    if 'file' not in request.files:\n",
        "        return redirect(request.url)\n",
        "    file = request.files['file']\n",
        "    if file.filename == '':\n",
        "        return redirect(request.url)\n",
        "    if file:\n",
        "        video_path = os.path.join(\"/content\", file.filename)\n",
        "        file.save(video_path)\n",
        "        process_video(video_path)\n",
        "\n",
        "        results = []\n",
        "        total_fake_confidence = 0\n",
        "        total_real_confidence = 0\n",
        "        fake_count = 0\n",
        "        real_count = 0\n",
        "\n",
        "        for filename in os.listdir(crop_image_file):\n",
        "            if filename.endswith('.jpg'):\n",
        "                image_path = os.path.join(crop_image_file, filename)\n",
        "                real_fake_label, real_fake_confidence, error_probabilities = predict_image(model, image_path)\n",
        "                results.append({\n",
        "                    'filename': filename,\n",
        "                    'real_fake_label': real_fake_label,\n",
        "                    'real_fake_confidence': real_fake_confidence,\n",
        "                    'error_probabilities': error_probabilities\n",
        "                })\n",
        "\n",
        "                if real_fake_label == 'Fake':\n",
        "                    total_fake_confidence += real_fake_confidence\n",
        "                    fake_count += 1\n",
        "                else:\n",
        "                    total_real_confidence += real_fake_confidence\n",
        "                    real_count += 1\n",
        "\n",
        "        # Calculate the average confidence for fake and real labels\n",
        "        avg_fake_confidence = total_fake_confidence / fake_count if fake_count > 0 else 0\n",
        "        avg_real_confidence = total_real_confidence / real_count if real_count > 0 else 0\n",
        "\n",
        "        # Generate styled HTML output\n",
        "        output = '''\n",
        "        <style>\n",
        "            body {\n",
        "                font-family: Arial, sans-serif;\n",
        "                background-color: #c3d4e389;\n",
        "                margin: 0;\n",
        "                padding: 0;\n",
        "\n",
        "\n",
        "            }\n",
        "            .container {\n",
        "                width: 80%;\n",
        "                margin: auto;\n",
        "                background-color: #fff;\n",
        "                padding: 20px;\n",
        "                box-shadow: 0 0 10px rgba(0, 0, 0, 0.1);\n",
        "                border-radius: 8px;\n",
        "                margin-top: 30px;\n",
        "                display:flex;\n",
        "                flex-direction:column;\n",
        "                align-items:center;\n",
        "            }\n",
        "            h2 {\n",
        "                color: #333;\n",
        "                text-align: center;\n",
        "                border-bottom: 2px solid #ddd;\n",
        "                padding-bottom: 10px;\n",
        "                margin-bottom: 20px;\n",
        "                color: #343a40;\n",
        "                background-image: linear-gradient(to top ,rgb(31, 83, 253),rgb(31, 179, 253));\n",
        "                -webkit-background-clip: text;\n",
        "                -webkit-text-fill-color: transparent;\n",
        "            }\n",
        "            .cart {\n",
        "                list-style-type: none;\n",
        "                padding: 0;\n",
        "                display: flex;\n",
        "                flex-wrap: wrap;\n",
        "                align-items:center;\n",
        "                justify-content:space-around;\n",
        "                margin: 0;\n",
        "                gap: 10px; /* Add spacing between items */\n",
        "            }\n",
        "            .cart li {\n",
        "                flex: 1 0 calc(33.333% - 20px); /* Adjust width for three columns with space for gap */\n",
        "                box-sizing: border-box;\n",
        "                padding: 10px;\n",
        "                margin-bottom: 20px;\n",
        "                background-color: #f9f9f9;\n",
        "                border: 1px solid #ddd;\n",
        "                border-radius: 5px;\n",
        "            }\n",
        "            .cart li:nth-child(odd) {\n",
        "                background-color: #e9e9e9; /* Alternate background color */\n",
        "            }\n",
        "            .cart li:nth-child(even) {\n",
        "                background-color: #f4f4f4; /* Alternate background color */\n",
        "            }\n",
        "            ul, li ul {\n",
        "                list-style: none;\n",
        "                padding: 0;\n",
        "                margin: 0;\n",
        "            }\n",
        "            li ul li {\n",
        "                background-color: #fff;\n",
        "                border: none;\n",
        "                padding: 5px;\n",
        "            }\n",
        "            h3 {\n",
        "                color: #555;\n",
        "                text-align: center;\n",
        "                margin-top: 20px;\n",
        "            }\n",
        "        </style>\n",
        "        <div class=\"container\">\n",
        "            <h2>Results:</h2>\n",
        "        '''\n",
        "        output += f\"<h3>Average Fake Confidence: {avg_fake_confidence:.2f}%</h3>\"\n",
        "        output += \"<ul class='cart'>\"\n",
        "        for result in results:\n",
        "            output += \"<ul>\"\n",
        "            output += f\"<li>{result['filename']} - <strong>{result['real_fake_label']}</strong> (Confidence: {result['real_fake_confidence']:.2f}%)\"\n",
        "            if result['error_probabilities']:\n",
        "                output += \"<ul>\"\n",
        "                for error, prob in result['error_probabilities'].items():\n",
        "                    output += f\"<li>{error}: {prob:.2f}%</li>\"\n",
        "                output += \"</ul>\"\n",
        "            output += \"</li>\"\n",
        "            output += \"</ul>\"\n",
        "\n",
        "        output += \"</ul>\"\n",
        "        #output += f\"<h3>Average Fake Confidence: {avg_fake_confidence:.2f}%</h3>\"\n",
        "        #output += f\"<h3>Average Real Confidence: {avg_real_confidence:.2f}%</h3>\"\n",
        "        output += \"</div>\"\n",
        "\n",
        "        return output\n",
        "\n",
        "# Open a tunnel on port 5000\n",
        "authtoken = \"2lYEWnzYTbSdtqk1UH2WnQx2O7y_TNywAcFM1rP4Gr8yQxjP\"  # Use your ngrok auth token\n",
        "ngrok.set_auth_token(authtoken)\n",
        "public_url = ngrok.connect(5000)\n",
        "print(f\" * ngrok tunnel \\\"{public_url}\\\" -> \\\"http://127.0.0.1:5000\\\"\")\n",
        "\n",
        "# Run the Flask app\n",
        "if __name__ == '__main__':\n",
        "    app.run()"
      ],
      "metadata": {
        "id": "_MAUSmWUyIph",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fe7ab2d4-5776-40a5-b82e-e6501e702eee"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " * ngrok tunnel \"NgrokTunnel: \"https://5adf-34-91-221-99.ngrok-free.app\" -> \"http://localhost:5000\"\" -> \"http://127.0.0.1:5000\"\n",
            " * Serving Flask app '__main__'\n",
            " * Debug mode: off\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:werkzeug:\u001b[31m\u001b[1mWARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.\u001b[0m\n",
            " * Running on http://127.0.0.1:5000\n",
            "INFO:werkzeug:\u001b[33mPress CTRL+C to quit\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " * Running on http://cda2-34-91-221-99.ngrok-free.app\n",
            " * Traffic stats available on http://127.0.0.1:4040\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:werkzeug:127.0.0.1 - - [03/Sep/2024 17:41:48] \"GET / HTTP/1.1\" 200 -\n",
            "INFO:werkzeug:127.0.0.1 - - [03/Sep/2024 17:41:48] \"\u001b[33mGET /static/scripts.js HTTP/1.1\u001b[0m\" 404 -\n",
            "INFO:werkzeug:127.0.0.1 - - [03/Sep/2024 17:41:48] \"GET /static/styles.css HTTP/1.1\" 200 -\n",
            "INFO:werkzeug:127.0.0.1 - - [03/Sep/2024 17:41:50] \"\u001b[33mGET /favicon.ico HTTP/1.1\u001b[0m\" 404 -\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 153ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-50-13f88bf1a5c3>:76: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
            "  real_fake_prob = float(predictions[0][0])\n",
            "<ipython-input-50-13f88bf1a5c3>:77: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
            "  pixelation_prob = float(predictions[1][0])\n",
            "<ipython-input-50-13f88bf1a5c3>:78: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
            "  shadow_prob = float(predictions[2][0])\n",
            "<ipython-input-50-13f88bf1a5c3>:79: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
            "  eye_asymmetry_prob = float(predictions[3][0])\n",
            "<ipython-input-50-13f88bf1a5c3>:80: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
            "  mouth_skewness_prob = float(predictions[4][0])\n",
            "<ipython-input-50-13f88bf1a5c3>:81: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
            "  nose_deviation_prob = float(predictions[5][0])\n",
            "<ipython-input-50-13f88bf1a5c3>:82: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
            "  chin_displacement_prob = float(predictions[6][0])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:werkzeug:127.0.0.1 - - [03/Sep/2024 17:43:23] \"POST /upload HTTP/1.1\" 200 -\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pyngrok import ngrok\n",
        "\n",
        "# Terminate open tunnels if any\n",
        "ngrok.kill()\n",
        "\n",
        "# Create a new tunnel\n",
        "public_url = ngrok.connect(5000)\n",
        "print(f\"Public URL: {public_url}\")"
      ],
      "metadata": {
        "id": "HXlroNRoC3dw",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "45190727-09aa-4213-bd0e-184c46791144"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Public URL: NgrokTunnel: \"https://fc79-34-91-221-99.ngrok-free.app\" -> \"http://localhost:5000\"\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Download the Ngrok package\n",
        "!wget -q -O ngrok.zip https://bin.equinox.io/c/4VmDzA7iaHb/ngrok-stable-linux-amd64.zip\n",
        "\n",
        "# Unzip the downloaded file\n",
        "!unzip ngrok.zip"
      ],
      "metadata": {
        "id": "tdxg9-azxj0i"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Replace YOUR_AUTH_TOKEN with your actual Ngrok token\n",
        "!./ngrok authtoken \"2lVh1lhns8BObYcyJgVN7F2QA7t_6MdTZ4u6dgyA3GDkee2L3\""
      ],
      "metadata": {
        "id": "DRk2r1hJxj3Y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "ebsMKpVNPvm3"
      }
    }
  ]
}